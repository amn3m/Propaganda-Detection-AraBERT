{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0887c186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â³ Loading Tokenizer from aubmindlab/bert-base-arabertv02...\n",
      "â³ Loading Optimized Model from C:\\Users\\Ahmed\\OneDrive\\Desktop\\NLP\\NLP_Project_Propaganda\\models\\arabert_optimized...\n",
      "âœ… System Ready!\n",
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "Could not create share link. Please check your internet connection or our status page: https://status.gradio.app.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import gradio as gr\n",
    "\n",
    "# 1. SETUP\n",
    "# Path to your TRAINED model\n",
    "model_path = r\"C:\\Users\\Ahmed\\OneDrive\\Desktop\\NLP\\NLP_Project_Propaganda\\models\\arabert_optimized\"\n",
    "# Name of the ORIGINAL tokenizer (we download this to avoid local file errors)\n",
    "tokenizer_name = \"aubmindlab/bert-base-arabertv02\"\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"â³ Loading Tokenizer from {tokenizer_name}...\")\n",
    "# FIX: Load tokenizer from the web, but model from local folder\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "\n",
    "print(f\"â³ Loading Optimized Model from {model_path}...\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path).to(device)\n",
    "print(\"âœ… System Ready!\")\n",
    "\n",
    "# 2. Define the Prediction Function\n",
    "def predict_propaganda(text):\n",
    "    # Prepare text\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128).to(device)\n",
    "    \n",
    "    # Get Prediction\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "        probabilities = torch.softmax(logits, dim=1)\n",
    "    \n",
    "    # Get Scores\n",
    "    # Class 0 = Non-Propaganda, Class 1 = Propaganda\n",
    "    non_prop_score = probabilities[0][0].item()\n",
    "    prop_score = probabilities[0][1].item()\n",
    "    \n",
    "    return {\n",
    "        \"Non-Propaganda (Ù…Ø­Ø§ÙŠØ¯)\": non_prop_score, \n",
    "        \"Propaganda (Ø¯Ø¹Ø§ÙŠØ©)\": prop_score\n",
    "    }\n",
    "\n",
    "# 3. Create the Interface\n",
    "demo = gr.Interface(\n",
    "    fn=predict_propaganda,\n",
    "    inputs=gr.Textbox(lines=3, placeholder=\"Ø£Ø¯Ø®Ù„ Ø§Ù„Ù†Øµ Ù‡Ù†Ø§... (Enter Arabic text here)\"),\n",
    "    outputs=gr.Label(num_top_classes=2),\n",
    "    title=\"ğŸ›¡ï¸ Arabic Propaganda Detector (AraBERT)\",\n",
    "    description=\"This AI detects if a text regarding the Gaza war contains propaganda techniques.\",\n",
    "    examples=[\n",
    "        [\"Ù‚Ø§Ù…Øª Ø§Ù„Ù‚ÙˆØ§Øª Ø§Ù„Ø¥Ø³Ø±Ø§Ø¦ÙŠÙ„ÙŠØ© Ø¨Ù‚ØµÙ Ù…Ø¯Ø±Ø³Ø© ØªØ¤ÙˆÙŠ Ù†Ø§Ø²Ø­ÙŠÙ† ÙÙŠ ØºØ²Ø©\"],  \n",
    "        [\"Ø§Ù„Ø¹Ø¯Ùˆ Ø§Ù„ØµÙ‡ÙŠÙˆÙ†ÙŠ Ø§Ù„ØºØ§Ø´Ù… ÙŠØ±ØªÙƒØ¨ Ù…Ø¬Ø§Ø²Ø± ÙˆØ­Ø´ÙŠØ© Ø¶Ø¯ Ø§Ù„Ù…Ø¯Ù†ÙŠÙŠÙ† Ø§Ù„Ø£Ø¨Ø±ÙŠØ§Ø¡\"], \n",
    "    ]\n",
    ")\n",
    "\n",
    "# 4. Launch!\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2b0593",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
